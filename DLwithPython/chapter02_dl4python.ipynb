{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d342f5e",
   "metadata": {},
   "source": [
    "# The mathematical building blocks of neural networks "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41af1b67",
   "metadata": {},
   "source": [
    "## A First Look at NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3ad8037b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc7b05af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the mnist dataset in Keras\n",
    "(train_X, train_y), (test_X, test_y) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874903af",
   "metadata": {},
   "source": [
    "Transform it into `float32` array of shape `60000,28*28`,\n",
    "and `10000,28*28` with a values between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ba6958d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preprocessing\n",
    "train_X = train_X.reshape((60000, 28*28))\n",
    "train_X = train_X.astype('float32') / 255\n",
    "\n",
    "test_X = test_X.reshape((10000, 28*28))\n",
    "test_X = test_X.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87dd259b",
   "metadata": {},
   "source": [
    "layers--Think a layers of Hidden neurons work as a filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1137cd21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-05 15:27:35.114829: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-02-05 15:27:35.115532: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "# build network architecture\n",
    "nn = keras.Sequential([\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb9ab40",
   "metadata": {},
   "source": [
    "- optimizer--The mechanism through which the model will update itself based on the training data it sees\n",
    "- loss function--How the model will be able to measure its performance on the training data, and thus how it will be able steer itself in the right direction\n",
    "- metrics--Monitor during training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ed210fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile step\n",
    "nn.compile(optimizer='rmsprop',\n",
    "           loss='sparse_categorical_crossentropy',\n",
    "           metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b13237",
   "metadata": {},
   "source": [
    "To train a model in `Keras` is done via call to the model's `fit()` \n",
    "method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4da57ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0288 - accuracy: 0.9913\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0224 - accuracy: 0.9931\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0168 - accuracy: 0.9956\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0128 - accuracy: 0.9960\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0102 - accuracy: 0.9969\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0084 - accuracy: 0.9977\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0060 - accuracy: 0.9983\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0051 - accuracy: 0.9987\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0037 - accuracy: 0.9991\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0032 - accuracy: 0.9991\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x169b7d190>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting the model\n",
    "nn.fit(train_X, train_y, epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b120b81",
   "metadata": {},
   "source": [
    "Using trained model to predic class probabilities for new digits-images\n",
    "that in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b0d1fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "9.974448e-25\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# using the model to make prediction\n",
    "test_digits = test_X[0:10]\n",
    "predictions = nn.predict(test_digits)\n",
    "\n",
    "print(predictions[6].argmax())\n",
    "print(predictions[0][6])\n",
    "\n",
    "# ground truth\n",
    "print(test_y[6])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dea7d44",
   "metadata": {},
   "source": [
    "Checking how good is our model at classifying such never-before-seen digits? by calling model's `evaluate() ` method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "709f52a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 36/313 [==>...........................] - ETA: 1s - loss: 0.0694 - accuracy: 0.9852 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-05 15:29:02.020242: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0768 - accuracy: 0.9822\n",
      "Test accuracy: 0.982200026512146\n"
     ]
    }
   ],
   "source": [
    "# evaluating the model on new data\n",
    "test_loss, test_acc = nn.evaluate(test_X, test_y)\n",
    "print(f'Test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8c5778",
   "metadata": {},
   "source": [
    "## Data representations for neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5543706b",
   "metadata": {},
   "source": [
    "A tensors are a generalization of matrices to an arbitrary number of dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1de7ac8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scalars\n",
    "# a tensor that contains only one number\n",
    "x = np.array(26)\n",
    "x.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1bf9720e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vectors\n",
    "# an array of numbers\n",
    "x = np.array((8, 26))\n",
    "x.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9faca0e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# matrices\n",
    "# an array of vectors \n",
    "x = np.array([[5, 78, 2, 34, 0],\n",
    "              [6, 79, 3, 35, 1],\n",
    "              [7, 80, 4, 36, 2]])\n",
    "x.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d16bfd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# higher dimension tensor\n",
    "x = np.array([[[5, 78, 2, 34, 0],\n",
    "               [6, 79, 3, 35, 1],\n",
    "               [7, 80, 4, 36, 2]],\n",
    "             [[5, 78, 2, 34, 0],\n",
    "               [6, 79, 3, 35, 1],\n",
    "               [7, 80, 4, 36, 2]],\n",
    "             [[5, 78, 2, 34, 0],\n",
    "               [6, 79, 3, 35, 1],\n",
    "               [7, 80, 4, 36, 2]]])\n",
    "x.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06994015",
   "metadata": {},
   "source": [
    "Key attributes:\n",
    "A tensor is defined by three key attributes: `number of axes`, `shape`, `data type`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e89bc89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of axes1: 3\n",
      "shape: (3, 3, 5)\n",
      "data types: int64\n"
     ]
    }
   ],
   "source": [
    "# key attr\n",
    "print('number of axes1:', x.ndim)\n",
    "print('shape:', x.shape)\n",
    "print('data types:', x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2f20468d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image label: 4\n"
     ]
    }
   ],
   "source": [
    "# displaying the digit\n",
    "# loading the mnist dataset in Keras\n",
    "(train_X, train_y), (test_X, test_y) = mnist.load_data()\n",
    "\n",
    "digit = test_X[6]\n",
    "plt.imshow(digit, cmap=plt.cm.binary)\n",
    "plt.show()\n",
    "\n",
    "print('image label:', test_y[6])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5677c2a7",
   "metadata": {},
   "source": [
    "### Manipulating tensors in Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa6a4395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 28, 28)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# slicing \n",
    "my_slice = train_X[10:100]\n",
    "my_slice.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f25330",
   "metadata": {},
   "source": [
    "### The notion of data batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4c01137d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 28, 28)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch \n",
    "batch1 = train_X[:128]\n",
    "batch1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0abec8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# next batch\n",
    "batch2 = train_X[128:128*2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "55e61574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the nth batch\n",
    "n = 3\n",
    "batch_size = 128\n",
    "\n",
    "batchn = train_X[n*batch_size:(n+1)*batch_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c401d708",
   "metadata": {},
   "source": [
    "### Real-world example of data tensor\n",
    "- `vector data`--(**samples**, **features**)\n",
    "- `timeseries data or sequence data`--(**samples**, **timesteps**, **features**)\n",
    "- `Images`--(**samples**, **height**, **width**, **channels**)\n",
    "- `Videos`--(**samples**, **frames**, **height**, **width**, **channels**)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10cb5deb",
   "metadata": {},
   "source": [
    "### Tensor operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a56fa5ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.13553474 0.53287657 ... 1.81073787 0.23288961 0.0660923 ]\n",
      " [0.         0.         0.         ... 1.1599795  1.94013514 0.67518594]\n",
      " ...\n",
      " [0.         0.         0.99739962 ... 0.         0.37444534 0.        ]\n",
      " [0.21347639 0.52137885 0.         ... 0.76667469 0.         0.        ]\n",
      " [0.         1.1735978  0.55814185 ... 1.13314113 0.99315031 0.4343458 ]]\n"
     ]
    }
   ],
   "source": [
    "# element-wise operations\n",
    "x = np.random.randn(20, 100)\n",
    "y = np.random.randn(20, 100)\n",
    "\n",
    "# relu activation\n",
    "z = np.maximum(x, 0)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5665c6e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 10)\n"
     ]
    }
   ],
   "source": [
    "# broadcasting\n",
    "# axes are added to the smaller tensor to match the ndim of the largere tensor\n",
    "# the smaller tensor is repeated alongside these new axes to math the full shape of large tensor\n",
    "x = np.random.randn(32, 10)\n",
    "y = np.random.randn(10)\n",
    "\n",
    "addition = x + y\n",
    "print(addition.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4cf93b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.5932764023259334\n"
     ]
    }
   ],
   "source": [
    "# tensor product \n",
    "x = np.random.randn(32)\n",
    "y = np.random.randn(32)\n",
    "\n",
    "z = np.dot(x, y)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7782e5bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape: (3, 2)\n",
      "reshape x: (6, 1)\n",
      "transpose x: (2, 3)\n"
     ]
    }
   ],
   "source": [
    "# tensor reshpaing\n",
    "x = np.array([[0, 1],\n",
    "              [2, 3],\n",
    "              [4, 5]])\n",
    "print('x shape:', x.shape)\n",
    "xreshape = x.reshape((6,1))\n",
    "print('reshape x:', xreshape.shape)\n",
    "xtranspose = x.T\n",
    "print('transpose x:', xtranspose.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91169db",
   "metadata": {},
   "source": [
    "### Geometric interpretation of tensor operation\n",
    "- `Translation`--Adding a vector to a point will move the point by a fixed amount in a fixed direction.\n",
    "- `Rotation`--A counterclockwise rotation of a 2D vector by an angle theta can be achieved via a dot product with 2 x 2 matrix **R** = `[[cos(theta),-sin(theta)],[sin(theta), cos[theta])`\n",
    "- `Scaling`--A vertical and horizontal scaling of the image can be achieved via a dot product with 2 x 2 matrix **S** = `[[h_factor, 0], [0, v_factor]]`\n",
    "- `Linear tranfrom` A dot product with an arbitrary matrix implements a linear transform.\n",
    "- `Affine transform` An affine transform is the combination of a linear transform and translation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b6abce",
   "metadata": {},
   "source": [
    "### The engine of nn: Gradient-based optimization\n",
    "output = relu(dot(input, W) + b)\\\n",
    "\\\n",
    "What happen inside this network?\n",
    "1. Initialize the weights and biase matrices, fill with small random values (*random initialization*)\n",
    "2. Run the model on x (*forward pass*) to obtain predictions, `y_pred`.\n",
    "3. Compute the loss of the model on the batch, a measure lost between `y_pred` and `y_true`.\n",
    "4. Update all weights and biases of th model in a way that slightly reduces the loss on this batch via `gradient descent`\n",
    "\\\n",
    "**Gradient descent** is th optimization technique tht powers modern nn. All of the functions used in the models transform thier input in a smooth and continuous way.\\\n",
    "**Derivative** simply is a slope of y change respectly to x `dy` / `dx`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a47edf",
   "metadata": {},
   "source": [
    "---\n",
    "## Reimplementing nn from scratch in Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "66881e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dense layer\n",
    "class Dense:\n",
    "    def __init__(self, inputs_size, output_size, activation):\n",
    "        self.activation = activation\n",
    "        \n",
    "        weights_shape = (inputs_size, output_size)\n",
    "        weights_init = tf.random.uniform(weights_shape,\n",
    "                                         minval=0, maxval=1e-1)\n",
    "        biases_init = tf.zeros(output_size, 1)\n",
    "        \n",
    "        self.W = tf.Variable(weights_init)\n",
    "        self.b = tf.Variable(biases_init)\n",
    "    \n",
    "    def __call__(self, inputs):\n",
    "            return self.activation(tf.matmul(\n",
    "                                    self.weights, inputs) + self.biases)\n",
    "        \n",
    "    @property\n",
    "    def weights(self):\n",
    "        return [self.W, self.b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7c739f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequential class\n",
    "class Sequential:\n",
    "    def __init__(self, layers):\n",
    "        self.layers = layers\n",
    "        \n",
    "    def __call__(self, inputs):\n",
    "        x = inputs\n",
    "        for layer in self.layers:\n",
    "            x = layers(x)\n",
    "            \n",
    "    @property\n",
    "    def weights(self):\n",
    "        weights = []\n",
    "        for layer in self.layers:\n",
    "            weights += layer.weights\n",
    "            \n",
    "        return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c3a6878a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch generator\n",
    "class BatchGenerator:\n",
    "    def __init__(self, images, labels, batch_size=128):\n",
    "        assert len(images) == len(labels)\n",
    "        self.idx = 0\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.num_batches = math.ceil(len(images) / batch_size)\n",
    "        \n",
    "    def next(self):\n",
    "        images = self.images[self.idx : self.idx + self.batch_size]\n",
    "        labels = self.labels[self.idx : self.idx + self.batch_size]\n",
    "        self.idx += self.batch_size\n",
    "        return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6c900b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a nn model\n",
    "model = Sequential([\n",
    "    Dense(inputs_size=784, output_size=512, activation=tf.nn.relu),\n",
    "    Dense(inputs_size=512, output_size=10, activation=tf.nn.softmax)\n",
    "])\n",
    "assert len(model.weights) == 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9a033308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# running one training step\n",
    "def one_training_step(model, images_batch, labels_batch):\n",
    "    with tf.GradientTape() as tape:\n",
    "        pred = model(images_batch)\n",
    "        per_sample_losses = tf.keras.loss.sparse_categorical_crossentropy(\n",
    "        labels_batch, prediction)\n",
    "        # calculate average loss\n",
    "        average_loss = tf.reduce_mean(per_sample_losses)\n",
    "    \n",
    "    # gradient descent\n",
    "    grads = tape.gradient(average_loss, model.weights)\n",
    "    update_weights(grads, model.weights)\n",
    "    \n",
    "    return average_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d03d98f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_weights(gradient, weights):\n",
    "    for g, w in zip(gradient, weights):\n",
    "        w.assign_sub(g * learning_rate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "one4all",
   "language": "python",
   "name": "one4all"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
