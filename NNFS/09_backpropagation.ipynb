{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "89efdaa5-8279-410d-88e9-160eba9a7fb2",
      "metadata": {
        "id": "89efdaa5-8279-410d-88e9-160eba9a7fb2"
      },
      "source": [
        "# Backpropagation\n",
        "In back prop, the NN adjusts it parameters propotionate to the erro in its guess. It does this by traversing backwards from the output, collecting the derivatives of the error with respect to the parameters of the function, and optimizing the parameters using `gradient descent`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "8f7cad4f-6e26-4304-be54-0e9deed5712a",
      "metadata": {
        "id": "8f7cad4f-6e26-4304-be54-0e9deed5712a",
        "outputId": "d250f1bb-f5ec-47d1-d629-4be96f74f431",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.7.12\n",
            "1.19.5\n",
            "3.2.2\n"
          ]
        }
      ],
      "source": [
        "import platform\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(platform.python_version())\n",
        "print(np.__version__)\n",
        "print(matplotlib. __version__)\n",
        "\n",
        "#python version 3.9.7\n",
        "#numpy version 1.21.2\n",
        "#matplotlib version 3.5.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "48f71277-d3ca-4173-9a56-9bde75270244",
      "metadata": {
        "id": "48f71277-d3ca-4173-9a56-9bde75270244",
        "outputId": "6c859539-feac-41f8-b96c-421e62db4fb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-061803531e11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'z1' is not defined"
          ]
        }
      ],
      "source": [
        "# full forward pass with relu\n",
        "# one traning example with three input features and three neurons\n",
        "\n",
        "x = [1.0, -2.0, 3.0]\n",
        "w = [-3.0, -1.0, 2.0]\n",
        "b = 1.0\n",
        "\n",
        "z = np.dot(w, x) + b\n",
        "a = max(z1, 0)\n",
        "print(a)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06b2db4d-1551-402b-82a7-a3c8b154f3e5",
      "metadata": {
        "id": "06b2db4d-1551-402b-82a7-a3c8b154f3e5"
      },
      "source": [
        "Lossely interpreted as: `ReLU[sum(inputs * weights) + bias]`\\\n",
        "Rewite the equation to the form that will allow us to determine how to calculate the derivatives more easily: `y` = `ReLU(sum(mul(x, w), b))`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "54a9f37d-c728-4a19-af44-6fded40a0005",
      "metadata": {
        "id": "54a9f37d-c728-4a19-af44-6fded40a0005"
      },
      "outputs": [],
      "source": [
        "# derivative of the relu function with respect to z\n",
        "relu_dz = (1 if z > 0 else 0.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "42fd38d3-3a71-4929-848d-4136622cc158",
      "metadata": {
        "id": "42fd38d3-3a71-4929-848d-4136622cc158",
        "outputId": "09742ec8-dc2e-4e04-fea6-a2b054bb52ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-25452139e9ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mdrelu_dxw2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdrelu_dz\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdsum_dxw2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mdrelu_db\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdrelu_dz\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdsum_db\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrelu_dx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrelu_dx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrelu_dx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrelu_db\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# Partial derivatives of the multiplication, the chain rule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'drelu_dx0' is not defined"
          ]
        }
      ],
      "source": [
        "# backpass\n",
        "# the derivative from the next layer\n",
        "dvalue = 1.0\n",
        "\n",
        "# derivative of relu and the chain rule\n",
        "drelu_dz = dvalue * relu_dz\n",
        "print(drelu_dz)\n",
        "\n",
        "# partial derivatives of the dot product, the chain rule\n",
        "dsum_dxw0 = 1\n",
        "dsum_dxw1 = 1\n",
        "dsum_dxw2 = 1\n",
        "dsum_db = 1\n",
        "drelu_dxw0 = drelu_dz * dsum_dxw0\n",
        "drelu_dxw1 = drelu_dz * dsum_dxw1\n",
        "drelu_dxw2 = drelu_dz * dsum_dxw2\n",
        "drelu_db = drelu_dz * dsum_db\n",
        "print(drelu_dx0, drelu_dx1, drelu_dx2, drelu_db)\n",
        "\n",
        "# Partial derivatives of the multiplication, the chain rule \n",
        "dmul_dx0 = w[0] \n",
        "dmul_dx1 = w[1] \n",
        "dmul_dx2 = w[2] \n",
        "dmul_dw0 = x[0] \n",
        "dmul_dw1 = x[1] \n",
        "dmul_dw2 = x[2] \n",
        "drelu_dx0 = drelu_dxw0 * dmul_dx0 \n",
        "drelu_dw0 = drelu_dxw0 * dmul_dw0 \n",
        "drelu_dx1 = drelu_dxw1 * dmul_dx1 \n",
        "drelu_dw1 = drelu_dxw1 * dmul_dw1 \n",
        "drelu_dx2 = drelu_dxw2 * dmul_dx2 \n",
        "drelu_dw2 = drelu_dxw2 * dmul_dw2 \n",
        "print(drelu_dx0, drelu_dw0, drelu_dx1, drelu_dw1, drelu_dx2, drelu_dw2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17317553-29d8-4866-a2ad-cdc9656f529d",
      "metadata": {
        "id": "17317553-29d8-4866-a2ad-cdc9656f529d"
      },
      "outputs": [],
      "source": [
        "# backward pass with multiple layers of neurons\n",
        "dvalues = np.ones((3, 3))\n",
        "\n",
        "# 3 sets of weights - one set for each neurons\n",
        "# 4 inputs features, thus 4 weights recall tha we keep weights transposed\n",
        "weights = np.array([[0.2, 0.8, -0.5, 1], \n",
        "                    [0.5, -0.91, 0.26, -0.5], \n",
        "                    [-0.26, -0.27, 0.17, 0.87]])\n",
        "\n",
        "# sum weights of given input and mul by the passed in gradient for this neuron\n",
        "dweights = np.dot(weights.T, dvalues)\n",
        "print(dX)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "33d9231c-0a9e-4068-8f02-d73e04fb5d8f",
      "metadata": {
        "id": "33d9231c-0a9e-4068-8f02-d73e04fb5d8f"
      },
      "outputs": [],
      "source": [
        "# forward pass and back pass \n",
        "dvalues = np.array([[1., 1., 1.,],\n",
        "                    [2., 2., 2.,],\n",
        "                    [3., 3., 3.,]])\n",
        "\n",
        "# 3 sets of inputs - samples\n",
        "inputs = np.array([[1, 2, 3, 2.5],\n",
        "                   [2., 5., -1., 2.],\n",
        "                   [-1.5, 2.7, 3.3, -0.8]])\n",
        "\n",
        "# 3 set of weights, one for each neurons\n",
        "#  4 inputs\n",
        "weights = np.array([[0.2, 0.8, -0.5, 1], \n",
        "                    [0.5, -0.91, 0.26, -0.5], \n",
        "                    [-0.26, -0.27, 0.17, 0.87]]).T\n",
        "\n",
        "# one bias for each neurons\n",
        "biases = np.array([[2, 3, 0.5]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "800277fa-7e91-481d-9fc3-dbdeb59244b1",
      "metadata": {
        "id": "800277fa-7e91-481d-9fc3-dbdeb59244b1",
        "outputId": "9fd99b13-226f-460c-e775-0ae93abb58c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.179515   0.5003665 -0.262746 ]\n",
            " [ 0.742093  -0.9152577 -0.2758402]\n",
            " [-0.510153   0.2529017  0.1629592]\n",
            " [ 0.971328  -0.5021842  0.8636583]]\n",
            "[[1.98489  2.997739 0.497389]]\n"
          ]
        }
      ],
      "source": [
        "# forward pass\n",
        "z = np.dot(inputs, weights) + biases\n",
        "a = np.maximum(z, 0) # relu activation function\n",
        "\n",
        "# back pass\n",
        "# from next layer passed to current layer during backprop\n",
        "drelu = a.copy()\n",
        "drelu[z <= 0] = 0\n",
        "\n",
        "# dense layer\n",
        "dweights = np.dot(inputs.T, drelu)\n",
        "dbiases = np.sum(drelu, axis=0, keepdims=True)\n",
        "\n",
        "weights += -0.001 * dweights\n",
        "biases += -0.001 * dbiases\n",
        "\n",
        "print(weights)\n",
        "print(biases)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "torch110",
      "language": "python",
      "name": "torch110"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "09_backpropagation.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}